{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating interface for packing the samples from the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from dataset import PhysioNet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packing import ExamplePacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== dataset configuration (mode) training ========\n",
      "\n",
      "======== k -> 3 ========\n",
      "======== sample_windows -> False ========\n",
      "======== include_rest -> True ========\n",
      "======== include_rest -> True ========\n",
      "======== extract_delta -> False ========\n",
      "======== activity_name -> all ========\n",
      "======== window_length -> 0.5 ========\n",
      "======== slide_delta -> 0.1 ========\n",
      "\n",
      "======== .......... ========\n",
      ".... found 1526 edf files ....\n",
      "---- data loaded from total of 10 -----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = PhysioNet(activity=\"all\",include_rest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 64, 321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.eeg_raw_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Pack(Dataset):\n",
    "    \"\"\"Interface for packing the examples into one sequence\"\"\"\n",
    "\n",
    "    def __init__(self,arr1,arr2,max_seq=4*160,max_search_depth=17) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        arr1 nparray : covariates of the dataset  \n",
    "        arr2 nparray : lables of the dataset           \n",
    "        \"\"\"\n",
    "\n",
    "        self.max_bin_size = max_seq\n",
    "        self.max_search_depth = max_search_depth\n",
    "        \n",
    "        self.arr1 = arr1\n",
    "        self.arr2 = arr2\n",
    "\n",
    "        # print(\"arr1 \",arr1)\n",
    "        # print(\"arr2 \",arr2)\n",
    "\n",
    "        self.packed_arr1,self.packed_arr2,self.packing_identifiers =  self.pack(arr1.copy(),arr2.copy())\n",
    "\n",
    "    def standardize_rows(self,arr):\n",
    "        \"\"\"\n",
    "        Standardize each row of the array to have a mean of 0 and a standard deviation of 1.\n",
    "        \n",
    "        Parameters:\n",
    "        arr (numpy.ndarray): Input array of shape (64, 80)\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Standardized array with the same shape as input\n",
    "        \"\"\"\n",
    "        # Calculate the mean and standard deviation for each row\n",
    "        row_mean = arr.mean(axis=1, keepdims=True)\n",
    "        row_std = arr.std(axis=1, keepdims=True)\n",
    "        \n",
    "        # Standardize each row\n",
    "        standardized_arr = (arr - row_mean) / row_std\n",
    "        \n",
    "        return standardized_arr\n",
    "    \n",
    "\n",
    "    def pack(self,samples,labels):\n",
    "\n",
    "        # samples = samples.copy()\n",
    "        # labels = labels.copy()\n",
    "\n",
    "\n",
    "        packing_identifiers = [] # used to trace back the position and length of original sequences in a packed sequence\n",
    "        bins = [] # contains the packed sequences\n",
    "        bin_labels = [] # contains the respective labels of the packed sequences\n",
    "\n",
    "\n",
    "\n",
    "        while len(samples) > self.max_search_depth:\n",
    "            \n",
    "            #### filling a new bin\n",
    "\n",
    "            bin_used = 0\n",
    "            depth_explored = 0\n",
    "\n",
    "\n",
    "            identifier = np.full(shape=(self.max_bin_size),fill_value=-1).astype(np.float16)\n",
    "            # print(\"identifier.shape \",identifier.shape)\n",
    "            \n",
    "            tar_bin = np.full(shape=(self.arr1[0].shape[0],self.max_bin_size),fill_value=-1).astype(np.float32)\n",
    "            tar_labels = np.full(shape=(self.max_bin_size,),fill_value=-1)\n",
    "\n",
    "            examples_added = 0 # counter for no of examples packed\n",
    "\n",
    "\n",
    "            while bin_used < self.max_bin_size and depth_explored <= self.max_search_depth and len(samples) > self.max_search_depth: \n",
    "                # print(\"len(samples) \",len(samples))\n",
    "                # print(\"depth_explored\",depth_explored)\n",
    "                \n",
    "                available_bin = self.max_bin_size - bin_used\n",
    "\n",
    "                curr_seq_length = samples[depth_explored].shape[-1]\n",
    "                # adding the sample into bin if it does not exceed the max size\n",
    "\n",
    "                if curr_seq_length <= available_bin :\n",
    "\n",
    "                    #### adding one sample to a bin\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "                    # print(\"samples[depth_explored] \",samples[depth_explored])\n",
    "                    # print(\"before tar_bin \",tar_bin[:,bin_used:bin_used+curr_seq_length])\n",
    "\n",
    "                    tar_bin[:,bin_used:bin_used+curr_seq_length] = self.standardize_rows(samples[depth_explored])\n",
    "                    \n",
    "                    # print(\"tar_bin afters \",tar_bin[:,bin_used:bin_used+curr_seq_length])\n",
    "                    # print(f\"Sample shape: {samples[depth_explored].shape}, Bin shape: {tar_bin[:, bin_used:bin_used + curr_seq_length].shape}\")\n",
    "\n",
    "\n",
    "                    tar_labels[bin_used:bin_used+curr_seq_length] = labels[depth_explored]\n",
    "\n",
    "                    samples.pop(depth_explored)\n",
    "                    label = labels.pop(depth_explored)\n",
    "\n",
    "                    # print(label)\n",
    "\n",
    "                    identifier[bin_used:bin_used+curr_seq_length] = examples_added\n",
    "\n",
    "    \n",
    "\n",
    "                    examples_added += 1\n",
    "\n",
    "                    depth_explored = 0\n",
    "                    bin_used  += curr_seq_length\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # if sample can not be added incrementing the depth_explored\n",
    "                    depth_explored += 1\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            packing_identifiers.append(identifier)\n",
    "            bins.append(tar_bin)\n",
    "            bin_labels.append(tar_labels)\n",
    "\n",
    "        return bins,bin_labels,packing_identifiers\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.packed_arr1)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.packed_arr1[idx].T,self.packed_arr2[idx],self.packing_identifiers[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = data.eeg_raw_windowed.shape[0] \n",
    "variable_lengths = (np.round(np.random.uniform(low=0.4,high=2.01,size=(total_samples)),decimals=1) * 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_lengths = variable_lengths.astype(np.int64)\n",
    "variable_len_covariates = []\n",
    "for idx,sample in enumerate(data.eeg_raw_x):    \n",
    "\n",
    "    variable_len_covariates.append(sample[:,:variable_lengths[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Pack(Dataset):\n",
    "    \"\"\"Interface for packing the examples into one sequence\"\"\"\n",
    "\n",
    "    def __init__(self,arr1,arr2,max_seq=4*160,max_search_depth=17) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        arr1 nparray : covariates of the dataset  \n",
    "        arr2 nparray : lables of the dataset           \n",
    "        \"\"\"\n",
    "\n",
    "        self.max_bin_size = max_seq\n",
    "        self.max_search_depth = max_search_depth\n",
    "        \n",
    "        self.arr1 = arr1\n",
    "        self.arr2 = arr2\n",
    "\n",
    "        # print(\"arr1 \",arr1)\n",
    "        # print(\"arr2 \",arr2)\n",
    "\n",
    "        self.packed_arr1,self.packed_arr2,self.packing_identifiers =  self.pack(arr1.copy(),arr2.copy())\n",
    "\n",
    "    def standardize_rows(self,arr):\n",
    "        \"\"\"\n",
    "        Standardize each row of the array to have a mean of 0 and a standard deviation of 1.\n",
    "        \n",
    "        Parameters:\n",
    "        arr (numpy.ndarray): Input array of shape (64, 80)\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Standardized array with the same shape as input\n",
    "        \"\"\"\n",
    "        # Calculate the mean and standard deviation for each row\n",
    "        row_mean = arr.mean(axis=1, keepdims=True)\n",
    "        row_std = arr.std(axis=1, keepdims=True)\n",
    "        \n",
    "        # Standardize each row\n",
    "        standardized_arr = (arr - row_mean) / row_std\n",
    "        \n",
    "        return standardized_arr\n",
    "    \n",
    "\n",
    "    def pack(self,samples,labels):\n",
    "\n",
    "        packing_identifiers = [] # used to trace back the position and length of original sequences in a packed sequence\n",
    "        bins = [] # contains the packed sequences\n",
    "        bin_labels = [] # contains the respective labels of the packed sequences\n",
    "\n",
    "\n",
    "        while len(samples) > self.max_search_depth:\n",
    "            \n",
    "            #### filling a new bin\n",
    "\n",
    "            bin_used = 0\n",
    "            depth_explored = 0\n",
    "\n",
    "\n",
    "            identifier = np.full(shape=(self.max_bin_size),fill_value=-1).astype(np.float16)\n",
    "            # print(\"identifier.shape \",identifier.shape)\n",
    "            \n",
    "            tar_bin = np.full(shape=(self.arr1[0].shape[0],self.max_bin_size),fill_value=-1).astype(np.float32)\n",
    "            tar_labels = np.full(shape=(self.max_bin_size,),fill_value=-1)\n",
    "\n",
    "            examples_added = 0 # counter for no of examples packed\n",
    "\n",
    "\n",
    "            while bin_used < self.max_bin_size and depth_explored <= self.max_search_depth and len(samples) > self.max_search_depth: \n",
    "                # print(\"len(samples) \",len(samples))\n",
    "                # print(\"depth_explored\",depth_explored)\n",
    "                \n",
    "                available_bin = self.max_bin_size - bin_used\n",
    "\n",
    "                curr_seq_length = samples[depth_explored].shape[-1]\n",
    "                # adding the sample into bin if it does not exceed the max size\n",
    "\n",
    "                if curr_seq_length <= available_bin :\n",
    "\n",
    "                    #### adding one sample to a bin\n",
    "\n",
    "\n",
    "                    \n",
    "                    # print(\"samples[depth_explored] \",samples[depth_explored])\n",
    "                    # print(\"before tar_bin \",tar_bin[:,bin_used:bin_used+curr_seq_length])\n",
    "\n",
    "                    tar_bin[:,bin_used:bin_used+curr_seq_length] = self.standardize_rows(samples[depth_explored])\n",
    "                    \n",
    "                    # print(\"tar_bin afters \",tar_bin[:,bin_used:bin_used+curr_seq_length])\n",
    "                    # print(f\"Sample shape: {samples[depth_explored].shape}, Bin shape: {tar_bin[:, bin_used:bin_used + curr_seq_length].shape}\")\n",
    "\n",
    "\n",
    "                    tar_labels[bin_used:bin_used+curr_seq_length] = labels[depth_explored]\n",
    "\n",
    "                    samples.pop(depth_explored)\n",
    "                    labels.pop(depth_explored)\n",
    "\n",
    "                    # print(label)\n",
    "\n",
    "                    identifier[bin_used:bin_used+curr_seq_length] = examples_added\n",
    "\n",
    "                    examples_added += 1\n",
    "\n",
    "                    depth_explored = 0\n",
    "                    bin_used  += curr_seq_length\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # if sample can not be added incrementing the depth_explored\n",
    "                    depth_explored += 1\n",
    "            \n",
    "\n",
    "            packing_identifiers.append(identifier)\n",
    "            bins.append(tar_bin)\n",
    "            bin_labels.append(tar_labels)\n",
    "\n",
    "        return bins,bin_labels,packing_identifiers\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.packed_arr1)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.packed_arr1[idx].T,self.packed_arr2[idx],self.packing_identifiers[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 240)\n"
     ]
    }
   ],
   "source": [
    "for i in variable_len_covariates:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples,labels,identifiers = ExamplePacking.pack(samples=variable_len_covariates,labels=data.eeg_data_y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs, labs =ExamplePacking.unpack(samples,labels,identifiers,max_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs[0][0] == samples[0][0][:160]\n",
    "# seqs[1][0] == samples[0][0][160:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(samples),len(labels),len(identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_dataset = Pack(arr1=variable_len_covariates,arr2=list(data.eeg_y_windowed),max_seq=3*160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n",
      "(480, 64)\n"
     ]
    }
   ],
   "source": [
    "for packed in packed_dataset:\n",
    "    eeg,labels,iden = packed\n",
    "    print(eeg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask_batch(batch_example_list):\n",
    "    \"\"\"\n",
    "    Create an attention mask for a batch of sequences where different examples \n",
    "    within each sequence do not attend to each other.\n",
    "    \n",
    "    Args:\n",
    "    - batch_example_list (list of lists or 2D tensor): A batch of sequences \n",
    "      representing the examples, e.g., [[1, 1, 1, 2, 2], [1, 2, 2, 3, 3]]\n",
    "    \n",
    "    Returns:\n",
    "    - attention_mask (torch.Tensor): A 3D tensor (batch_size, seq_len, seq_len), \n",
    "                                      where 1 means positions can attend to each other,\n",
    "                                      and 0 means they cannot.\n",
    "    \"\"\"\n",
    "    # Convert the input list to a 2D tensor (batch_size, seq_len)\n",
    "    batch_example_list = np.array(batch_example_list)\n",
    "    sequence_tensor = torch.tensor(batch_example_list)\n",
    "    \n",
    "    # Create a comparison matrix for each batch: (batch_size, seq_len, seq_len)\n",
    "    attention_mask = (sequence_tensor.unsqueeze(1) == sequence_tensor.unsqueeze(2))\n",
    "    \n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import Temporal_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenc = Temporal_Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=packed_dataset,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 480, 64])\n",
      "torch.Size([8, 480])\n",
      "torch.Size([8, 480])\n",
      "masks.shape torch.Size([8, 480, 480])\n"
     ]
    }
   ],
   "source": [
    "for data in loader:\n",
    "    eeg, labels, identifiers = data \n",
    "    print(eeg.shape)  # Ensure it's (8, num_channels, signal_length)\n",
    "    print(labels.shape)  # Ensure this shape is as expected\n",
    "    print(identifiers.shape)  # Check shape of identifiers\n",
    "\n",
    "    # Create attention mask\n",
    "    masks = create_attention_mask_batch(identifiers)\n",
    "    print(\"masks.shape\", masks.shape)  # Ensure it's torch.Size([8, 480, 480])\n",
    "    masks = masks.repeat_interleave(8, dim=0)\n",
    "\n",
    "    # Forward pass with EEG data and mask\n",
    "    output = tenc(eeg, masks)\n",
    "\n",
    "    break  # Assuming you're breaking for debugging purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.5930e-01,  2.8274e-01, -1.1131e-01,  ...,  6.0622e-01,\n",
       "           3.0650e-01,  2.6195e+00],\n",
       "         [-6.1299e-01, -5.0991e-01, -7.9516e-01,  ...,  1.2648e+00,\n",
       "           3.0891e-01,  2.3436e+00],\n",
       "         [-7.9614e-01, -4.2468e-01, -1.3422e+00,  ...,  9.3737e-01,\n",
       "           8.0326e-01,  2.3346e+00],\n",
       "         ...,\n",
       "         [ 1.5788e-01, -2.0893e+00,  3.3944e-01,  ..., -1.5054e+00,\n",
       "           6.1906e-01,  1.4039e+00],\n",
       "         [-4.7075e-01, -2.0760e+00, -2.7877e-01,  ..., -1.6566e+00,\n",
       "          -2.4179e-01,  9.1007e-01],\n",
       "         [ 1.2799e-01, -1.7113e+00, -3.9512e-01,  ..., -2.0863e+00,\n",
       "          -2.9439e-01,  1.4370e+00]],\n",
       "\n",
       "        [[ 9.7499e-01, -5.3609e-01, -2.3439e-01,  ..., -1.4338e+00,\n",
       "          -9.0490e-01,  1.1090e+00],\n",
       "         [ 1.3554e+00,  2.7740e-02,  9.1268e-02,  ..., -9.9386e-01,\n",
       "          -5.8602e-01,  1.0366e+00],\n",
       "         [ 1.4709e+00, -1.2734e-01,  4.1962e-01,  ..., -8.5259e-01,\n",
       "          -9.7013e-02,  1.2469e+00],\n",
       "         ...,\n",
       "         [ 9.7218e-02, -2.2246e+00, -2.7186e-01,  ..., -1.6897e+00,\n",
       "          -3.7025e-02,  6.7824e-01],\n",
       "         [-2.9226e-01, -9.9778e-01,  4.1342e-01,  ..., -1.7118e+00,\n",
       "          -5.1671e-02,  1.6820e+00],\n",
       "         [-4.1613e-02, -2.1449e+00, -2.5241e-01,  ..., -1.4116e+00,\n",
       "          -3.2758e-01,  1.0966e+00]],\n",
       "\n",
       "        [[ 9.3030e-02,  2.5097e-01,  1.6234e-01,  ..., -1.2303e+00,\n",
       "          -1.3311e+00, -5.4306e-01],\n",
       "         [-2.3513e-01,  5.2562e-01,  1.0807e-01,  ..., -2.9918e-01,\n",
       "          -3.7776e-01, -1.0323e+00],\n",
       "         [-3.4111e-01,  1.7317e-01, -4.4344e-01,  ..., -7.0280e-01,\n",
       "          -5.0345e-01, -3.7999e-01],\n",
       "         ...,\n",
       "         [ 5.4036e-01, -1.7488e+00, -3.1746e-01,  ..., -2.1038e+00,\n",
       "           6.1561e-02,  1.1611e+00],\n",
       "         [ 6.2068e-01, -1.1188e+00, -1.4742e-01,  ..., -1.7313e+00,\n",
       "          -2.2466e-01,  1.0025e+00],\n",
       "         [ 1.2162e-01, -2.2972e+00, -6.9455e-01,  ..., -1.9343e+00,\n",
       "           5.4610e-01,  9.7954e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8.6075e-01,  1.5144e-01,  3.7675e-01,  ..., -1.3393e+00,\n",
       "          -7.2067e-01,  1.4449e+00],\n",
       "         [ 1.7608e+00,  1.2494e-01,  8.3635e-01,  ..., -1.0307e+00,\n",
       "          -1.0606e+00,  1.9759e+00],\n",
       "         [ 1.4533e+00, -4.2203e-01, -6.8926e-02,  ..., -5.6390e-01,\n",
       "          -1.4136e+00,  1.3336e+00],\n",
       "         ...,\n",
       "         [ 3.0977e-01, -2.1043e+00, -3.0568e-01,  ..., -1.3329e+00,\n",
       "           7.9654e-02,  6.8618e-01],\n",
       "         [ 1.8306e-01, -1.9884e+00, -3.1999e-01,  ..., -2.2107e+00,\n",
       "           1.3492e-01,  1.2626e+00],\n",
       "         [ 1.6629e-01, -2.0037e+00, -1.7616e-02,  ..., -1.0615e+00,\n",
       "           1.0185e+00,  1.4112e+00]],\n",
       "\n",
       "        [[ 1.8362e+00, -6.7753e-01, -1.8707e-01,  ..., -2.9533e-01,\n",
       "           1.1808e+00,  2.9571e-01],\n",
       "         [-1.0115e-01, -5.5882e-01, -6.7898e-02,  ..., -2.4785e-01,\n",
       "           7.9019e-01,  1.5903e+00],\n",
       "         [ 1.0451e-01, -1.0730e+00, -1.6075e-01,  ..., -6.9935e-01,\n",
       "           1.6269e+00,  1.5247e+00],\n",
       "         ...,\n",
       "         [ 4.2300e-01, -2.3079e+00,  7.6767e-02,  ..., -1.6469e+00,\n",
       "           2.5873e-01,  9.7651e-01],\n",
       "         [ 5.5854e-01, -2.3283e+00, -5.8276e-02,  ..., -1.4545e+00,\n",
       "           5.0723e-02,  4.5483e-01],\n",
       "         [ 2.1804e-01, -1.4985e+00,  7.5941e-02,  ..., -1.8503e+00,\n",
       "          -1.3345e-01,  6.5083e-01]],\n",
       "\n",
       "        [[ 7.6148e-01, -5.7119e-01,  1.9437e-03,  ..., -1.7235e+00,\n",
       "          -5.0189e-01,  1.7063e+00],\n",
       "         [ 4.5385e-01, -5.4041e-01, -9.9489e-02,  ..., -1.9118e+00,\n",
       "          -4.7087e-01,  1.3786e+00],\n",
       "         [ 1.8639e-01, -1.7870e-01,  2.3004e-01,  ..., -2.0412e+00,\n",
       "          -4.8572e-01,  2.1465e+00],\n",
       "         ...,\n",
       "         [ 2.3737e-01, -2.5111e+00, -5.7674e-01,  ..., -1.6845e+00,\n",
       "           2.4769e-01,  1.8054e+00],\n",
       "         [ 6.0387e-01, -2.1342e+00, -8.0191e-02,  ..., -1.7765e+00,\n",
       "           6.2804e-01,  1.4943e+00],\n",
       "         [ 3.4632e-01, -1.1087e+00, -2.8187e-01,  ..., -1.9903e+00,\n",
       "          -5.8475e-01,  5.0360e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float16),\n",
       " array([464,   0, 240]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "identifiers[4],np.unique(identifiers[0],return_index=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(y,true_lables,identifiers,max_pool=True):\n",
    "    \"\"\"  \n",
    "    unpacks the sequence \n",
    "    \"\"\"\n",
    "    \n",
    "    unpacked_predictions = []    \n",
    "    unpacked_lables = []\n",
    "\n",
    "    max_pooled = []\n",
    "\n",
    "    idx = 0\n",
    "    for packed_sequence,seq_iden,labels in zip(y,identifiers,true_lables):\n",
    "        \n",
    "        seq_nums , locations= np.unique(seq_iden,return_index=True) \n",
    "        locations = locations.tolist() \n",
    "\n",
    "        # print(\"seq_nums \",seq_nums)\n",
    "        if seq_nums[0] == -1: # if there is any padding\n",
    "            # print(\"padding found\")\n",
    "            padding_start_loc = locations.pop(0)\n",
    "\n",
    "            pass\n",
    "        else:\n",
    "            # print(\"seq_iden.shape \",seq_iden.shape)\n",
    "            padding_start_loc = seq_iden.shape[0]\n",
    "            \n",
    "\n",
    "        locations.append(padding_start_loc)\n",
    "\n",
    "        # print(\"locations \",locations)\n",
    "        # idx += 1\n",
    "        # if idx == 10:\n",
    "        #     break\n",
    "\n",
    "        ## unpacking the sequence \n",
    "\n",
    "        for idx in range(len(locations)-1):\n",
    "            example_unpacked = packed_sequence[locations[idx]:locations[idx+1],:]\n",
    "            # print(\"unpack_seq.shape \",example_unpacked.shape)\n",
    "            unpacked_predictions.append(example_unpacked)\n",
    "\n",
    "            if max_pool == True:\n",
    "\n",
    "                max_pooled.append(torch.max(example_unpacked,dim=0).values)\n",
    "\n",
    "        ## unpacking the labels correspoding to the unpacked sequences\n",
    "        unpacked_lables.extend(labels[locations[:-1]].tolist())\n",
    "\n",
    "    if max_pool == True:\n",
    "        return max_pooled,unpacked_lables\n",
    "\n",
    "    return unpacked_predictions,unpacked_lables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.5930e-01,  2.8274e-01, -1.1131e-01,  ...,  6.0622e-01,\n",
       "           3.0650e-01,  2.6195e+00],\n",
       "         [-6.1299e-01, -5.0991e-01, -7.9516e-01,  ...,  1.2648e+00,\n",
       "           3.0891e-01,  2.3436e+00],\n",
       "         [-7.9614e-01, -4.2468e-01, -1.3422e+00,  ...,  9.3737e-01,\n",
       "           8.0326e-01,  2.3346e+00],\n",
       "         ...,\n",
       "         [ 1.5788e-01, -2.0893e+00,  3.3944e-01,  ..., -1.5054e+00,\n",
       "           6.1906e-01,  1.4039e+00],\n",
       "         [-4.7075e-01, -2.0760e+00, -2.7877e-01,  ..., -1.6566e+00,\n",
       "          -2.4179e-01,  9.1007e-01],\n",
       "         [ 1.2799e-01, -1.7113e+00, -3.9512e-01,  ..., -2.0863e+00,\n",
       "          -2.9439e-01,  1.4370e+00]],\n",
       "\n",
       "        [[ 9.7499e-01, -5.3609e-01, -2.3439e-01,  ..., -1.4338e+00,\n",
       "          -9.0490e-01,  1.1090e+00],\n",
       "         [ 1.3554e+00,  2.7740e-02,  9.1268e-02,  ..., -9.9386e-01,\n",
       "          -5.8602e-01,  1.0366e+00],\n",
       "         [ 1.4709e+00, -1.2734e-01,  4.1962e-01,  ..., -8.5259e-01,\n",
       "          -9.7013e-02,  1.2469e+00],\n",
       "         ...,\n",
       "         [ 9.7218e-02, -2.2246e+00, -2.7186e-01,  ..., -1.6897e+00,\n",
       "          -3.7025e-02,  6.7824e-01],\n",
       "         [-2.9226e-01, -9.9778e-01,  4.1342e-01,  ..., -1.7118e+00,\n",
       "          -5.1671e-02,  1.6820e+00],\n",
       "         [-4.1613e-02, -2.1449e+00, -2.5241e-01,  ..., -1.4116e+00,\n",
       "          -3.2758e-01,  1.0966e+00]],\n",
       "\n",
       "        [[ 9.3030e-02,  2.5097e-01,  1.6234e-01,  ..., -1.2303e+00,\n",
       "          -1.3311e+00, -5.4306e-01],\n",
       "         [-2.3513e-01,  5.2562e-01,  1.0807e-01,  ..., -2.9918e-01,\n",
       "          -3.7776e-01, -1.0323e+00],\n",
       "         [-3.4111e-01,  1.7317e-01, -4.4344e-01,  ..., -7.0280e-01,\n",
       "          -5.0345e-01, -3.7999e-01],\n",
       "         ...,\n",
       "         [ 5.4036e-01, -1.7488e+00, -3.1746e-01,  ..., -2.1038e+00,\n",
       "           6.1561e-02,  1.1611e+00],\n",
       "         [ 6.2068e-01, -1.1188e+00, -1.4742e-01,  ..., -1.7313e+00,\n",
       "          -2.2466e-01,  1.0025e+00],\n",
       "         [ 1.2162e-01, -2.2972e+00, -6.9455e-01,  ..., -1.9343e+00,\n",
       "           5.4610e-01,  9.7954e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8.6075e-01,  1.5144e-01,  3.7675e-01,  ..., -1.3393e+00,\n",
       "          -7.2067e-01,  1.4449e+00],\n",
       "         [ 1.7608e+00,  1.2494e-01,  8.3635e-01,  ..., -1.0307e+00,\n",
       "          -1.0606e+00,  1.9759e+00],\n",
       "         [ 1.4533e+00, -4.2203e-01, -6.8926e-02,  ..., -5.6390e-01,\n",
       "          -1.4136e+00,  1.3336e+00],\n",
       "         ...,\n",
       "         [ 3.0977e-01, -2.1043e+00, -3.0568e-01,  ..., -1.3329e+00,\n",
       "           7.9654e-02,  6.8618e-01],\n",
       "         [ 1.8306e-01, -1.9884e+00, -3.1999e-01,  ..., -2.2107e+00,\n",
       "           1.3492e-01,  1.2626e+00],\n",
       "         [ 1.6629e-01, -2.0037e+00, -1.7616e-02,  ..., -1.0615e+00,\n",
       "           1.0185e+00,  1.4112e+00]],\n",
       "\n",
       "        [[ 1.8362e+00, -6.7753e-01, -1.8707e-01,  ..., -2.9533e-01,\n",
       "           1.1808e+00,  2.9571e-01],\n",
       "         [-1.0115e-01, -5.5882e-01, -6.7898e-02,  ..., -2.4785e-01,\n",
       "           7.9019e-01,  1.5903e+00],\n",
       "         [ 1.0451e-01, -1.0730e+00, -1.6075e-01,  ..., -6.9935e-01,\n",
       "           1.6269e+00,  1.5247e+00],\n",
       "         ...,\n",
       "         [ 4.2300e-01, -2.3079e+00,  7.6767e-02,  ..., -1.6469e+00,\n",
       "           2.5873e-01,  9.7651e-01],\n",
       "         [ 5.5854e-01, -2.3283e+00, -5.8276e-02,  ..., -1.4545e+00,\n",
       "           5.0723e-02,  4.5483e-01],\n",
       "         [ 2.1804e-01, -1.4985e+00,  7.5941e-02,  ..., -1.8503e+00,\n",
       "          -1.3345e-01,  6.5083e-01]],\n",
       "\n",
       "        [[ 7.6148e-01, -5.7119e-01,  1.9437e-03,  ..., -1.7235e+00,\n",
       "          -5.0189e-01,  1.7063e+00],\n",
       "         [ 4.5385e-01, -5.4041e-01, -9.9489e-02,  ..., -1.9118e+00,\n",
       "          -4.7087e-01,  1.3786e+00],\n",
       "         [ 1.8639e-01, -1.7870e-01,  2.3004e-01,  ..., -2.0412e+00,\n",
       "          -4.8572e-01,  2.1465e+00],\n",
       "         ...,\n",
       "         [ 2.3737e-01, -2.5111e+00, -5.7674e-01,  ..., -1.6845e+00,\n",
       "           2.4769e-01,  1.8054e+00],\n",
       "         [ 6.0387e-01, -2.1342e+00, -8.0191e-02,  ..., -1.7765e+00,\n",
       "           6.2804e-01,  1.4943e+00],\n",
       "         [ 3.4632e-01, -1.1087e+00, -2.8187e-01,  ..., -1.9903e+00,\n",
       "          -5.8475e-01,  5.0360e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "x,y = unpack(y=output,true_lables=labels,identifiers=identifiers)\n",
    "idx += 1\n",
    "\n",
    "# if idx == 3:\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(80,64)\n",
    "torch.max(rand,dim=0).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., -1, -1, -1],\n",
       "        [ 0,  0,  0,  ..., -1, -1, -1],\n",
       "        [ 0,  0,  0,  ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.], dtype=float16), array([464,   0, 240]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(identifiers[0],return_index=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 480, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, batch_first=True)\n",
    "src_mask = torch.rand(32, 10, 10)\n",
    "\n",
    "# Repeat src_mask for the number of attention heads\n",
    "src_mask=torch.rand(32,10,10)\n",
    "src_mask = src_mask.repeat_interleave(8, dim=0)\n",
    "src = torch.rand(32,10 ,512)\n",
    "out = encoder_layer(src,src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The shape of the 3D attn_mask is torch.Size([8, 300, 300]), but should be (64, 300, 300).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtenc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Internship/code/sequence_packing_transformers/networks.py:59\u001b[0m, in \u001b[0;36mTemporal_Encoder.forward\u001b[0;34m(self, x, src_mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x,src_mask):\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# x should be shape : batch, signal_length,num_channels\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:714\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    712\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 714\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:722\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    721\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 722\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:5359\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5357\u001b[0m     correct_3d_size \u001b[38;5;241m=\u001b[39m (bsz \u001b[38;5;241m*\u001b[39m num_heads, tgt_len, src_len)\n\u001b[1;32m   5358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m correct_3d_size:\n\u001b[0;32m-> 5359\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the 3D attn_mask is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_3d_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_mask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The shape of the 3D attn_mask is torch.Size([8, 300, 300]), but should be (64, 300, 300)."
     ]
    }
   ],
   "source": [
    "tenc(torch.rand(size=(8,300,64)),torch.rand(8,300,300)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(elem)  <class 'torch.Tensor'>\n",
      "type(elem)  <class 'torch.Tensor'>\n",
      "torch.Size([80, 5]) torch.Size([80])\n",
      "torch.Size([20, 5]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def random_split_tensors(split_ratio, *tensors, seed=None):\n",
    "\n",
    "\n",
    "    assert all(tensor.size(0) == tensors[0].size(0) for tensor in tensors), \"All tensors must have the same first dimension.\"\n",
    "    for elem in tensors:\n",
    "        print(\"type(elem) \",type(elem))\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    indices = list(range(tensors[0].size(0)))\n",
    "    \n",
    "    # Split the indices for train and validation based on split_ratio\n",
    "    train_indices, val_indices = train_test_split(indices, train_size=split_ratio, random_state=seed)\n",
    "    \n",
    "    # Create train and validation splits for each tensor\n",
    "    split1 = []\n",
    "    split2 = []\n",
    "\n",
    "    for tensor in tensors:\n",
    "        train_split = tensor[train_indices]\n",
    "        val_split = tensor[val_indices]\n",
    "        \n",
    "        split1.append(train_split)\n",
    "        split2.append(val_split)\n",
    "    \n",
    "    return tuple((split1,split2))\n",
    "\n",
    "# Example usage:\n",
    "# tensor1 and tensor2 are example tensors with corresponding elements\n",
    "tensor1 = torch.randn(100, 5)  # e.g., 100 samples, 5 features each\n",
    "tensor2 = torch.randint(0, 2, (100,))  # e.g., 100 labels\n",
    "\n",
    "train_val_splits = random_split_tensors(0.8, tensor1, tensor2, seed=42)\n",
    "train_tensor1, val_tensor1 = train_val_splits[0]\n",
    "train_tensor2, val_tensor2 = train_val_splits[1]\n",
    "\n",
    "print(train_tensor1.shape, val_tensor1.shape)  # Train and val shapes for tensor1\n",
    "print(train_tensor2.shape, val_tensor2.shape)  # Train and val shapes for tensor2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
